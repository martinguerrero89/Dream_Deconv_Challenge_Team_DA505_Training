data=readRDS("./Data/train_samples.rds")
setwd("D:/Users/Marti/Desktop/Deconv challenge/Collaboration_phase")
data=readRDS("./Data/train_samples.rds")
head(data)
barplot(data[1,])
barplot(data[1:2,])
summary(data[1,])
min(data[1,])
max(data[1,])
mean(data[1,])
mean(data[1,],na.rm=TRUE)
data[1,]
mean(as.numeric(data[1,]),na.rm=TRUE)
median(as.numeric(data[1,]),na.rm=TRUE)
metadata = read.table("./Data/Deconv_training_datasets_tidy8.txt",
sep = "\t",
header = TRUE,
stringsAsFactors = FALSE
)
metadata
setwd("C:/Users/Usuario/Documents/GitHub/Dream_Deconv_Challenge_Team_DA505_Training")
data=readRDS("./input/train_samples.rds")
metadata = read.table("./input/Deconv_training_datasets_tidy.txt",
sep = "\t",
header = TRUE,
stringsAsFactors = FALSE
)
head(metadata)
metadata$treatment
table(metadata$treatment, metadata$coarsegrain)
table(metadata$treatment, metadata$family)
metadata= metadata[!(metadata$treatment=="yes" & (metadata$family == "CD4" | metadata$family=="CD8")),]
both= Reduce(intersect,list(metadata$samplename,colnames(data)))
data= data[,both]
data= data[rowSums(data)!=0,]
rownames(metadata)=metadata$samplename
metadata = metadata[both, ]
data = log2(data + 1)
#Table 1(resuming data)
library(table1)
table1(~batch + platform +treatment | coarsegrain,data=metadata)
table1(~batch + platform +treatment | finegrain,data=metadata)
S=sample(1:ncol(data),10)
boxplot(data[,S])
library(limma)
boxplot(voom(exp(data[,S]))$E)
library(preprocessCore)
boxplot(normalize.quantiles(as.matrix(data[,S])))
load("./Rhino_norm.R")
getwd()
load("./functions/Rhino_norm.R")
load("./functions/Rhino_norm.R")
source("./functions/Rhino_norm.R")
data=readRDS("./input/train_samples.rds")
metadata = read.table("./input/Deconv_training_datasets_tidy.txt",
sep = "\t",
header = TRUE,
stringsAsFactors = FALSE
)
metadata= metadata[!(metadata$treatment=="yes" & (metadata$family == "CD4" | metadata$family=="CD8")),]
both= Reduce(intersect,list(metadata$samplename,colnames(data)))
data= data[,both]
data= data[rowSums(data)!=0,]
rownames(metadata)=metadata$samplename
metadata = metadata[both, ]
saveRDS(data,file="./Data/train_samples.rds",compress= "xz")
saveRDS(data,file="./input/train_samples.rds",compress= "xz")
data2= read.csv("D:/Users/Marti/Desktop/Deconv challenge/PARA HARPO")
data2= read.csv("D:/Users/Marti/Desktop/Deconv challenge/PARA HARPO/training_data_ensg_tpm.csv")
head(data)
head(data2)
head(data[1:5,1:5])
head(data2[1:5,1:5])
dim(metadata)
write.table(metadata, "./input/Deconv_training_datasets_tidy2.txt", col.names = TRUE)
metadata = read.table("./input/Deconv_training_datasets_tidy.txt",
sep = "\t",
header = TRUE,
stringsAsFactors = FALSE
)
metadata2 = read.table("./input/Deconv_training_datasets_tidy2.txt",
sep = "\t",
header = TRUE,
stringsAsFactors = FALSE
)
metadata= metadata[!(metadata$treatment=="yes" & (metadata$family == "CD4" | metadata$family=="CD8")),]
both= Reduce(intersect,list(metadata$samplename,colnames(data)))
data= data[,both]
data= data[rowSums(data)!=0,]
rownames(metadata)=metadata$samplename
metadata = metadata[both, ]
write.table(metadata, "./input/Deconv_training_datasets_tidy2.txt")
metadata2 = read.table("./input/Deconv_training_datasets_tidy2.txt",
sep = "\t",
header = TRUE,
stringsAsFactors = FALSE
)
write.table(metadata, "./input/Deconv_training_datasets_tidy2.txt",header=TRUE)
?write.table
head(metadata)
head(metadata2)
write.table(metadata, "./input/Deconv_training_datasets_tidy2.txt",sep="\t")
metadata2 = read.table("./input/Deconv_training_datasets_tidy2.txt",
sep = "\t",
header = TRUE,
stringsAsFactors = FALSE
)
identical(metadata,metadata2)
write.table(metadata, "./input/Deconv_training_datasets_tidy.txt",header=TRUE)
write.table(metadata, "./input/Deconv_training_datasets_tidy.txt",sep="\t")
data=readRDS("./input/train_samples.rds")
metadata = read.table("./input/Deconv_training_datasets_tidy.txt",
sep = "\t",
header = TRUE,
stringsAsFactors = FALSE
)
data = log2(data + 1)
source("./functions/Rhino_norm.R")
mynorm4
X= apply(data,2,mynorm4)
boxplot(X[,S])
S=sample(1:ncol(data),10)
boxplot(X[,S])
Trainset = 1
Norm = "Dense_rank7" #Dense_rank,Dense_rank2,Dense_rank3, quantile, cps
Mix= "A"
Method = "glmnet" #glmnet svm
rm(Trainset)
rm(Norm)
rm(Mix)
rm(Method)
rm(lower.limit)
celltypes= unique(metadata$finegrain)
TrainSet= NULL
for(i in celltypes[celltypes!="other"]){
W=which(metadata$finegrain ==i)
TrainSet= c(TrainSet,sample(W,length(W)*0.7,replace=FALSE))
}
TrainExp= X[,TrainSet]
TrainClass= as.factor(metadata$finegrain[TrainSet])
TestExp= X[,-TrainSet]
#TestClass= metadata$coarsegrain[-TrainSet]
TestClass= metadata$finegrain[-TrainSet]
#cv     <- cv.glmnet(Xsubo,Yo,family="binomial",alpha=alpha)
library(glmnet)
cvfit=cv.glmnet(t(TrainExp), TrainClass, family="multinomial", type.multinomial = "grouped", parallel = TRUE)
P=predict(cvfit, newx = t(TestExp), s = "lambda.min", type = "class")
accuracy <- table(P, TestClass)
accuracy
acc <- sum(diag(accuracy))/sum(accuracy)
acc
acc <- sum(diag(accuracy[,rownames(accuracy != "others")]))/sum(accuracy[,colnames(accuracy != "others")])
acc
accuracy <- accuracy[rownames(accuracy) != "others", colnames(accuracy) != "others"]
accuracy
accuracy <- accuracy[rownames(accuracy) != "other", colnames(accuracy) != "other"]
accuracy
acc <- sum(diag(accuracy))/sum(accuracy)
acc
FEATS= coef(cvfit,s="lambda.min")
FEATS= do.call(cbind,FEATS)
def_FEATS= rownames(FEATS)[rowSums(FEATS)!=0][-1]
SampleCor= cor(X[def_FEATS,])
library(igraph)
SampleCorTrSubi=apply((SampleCor>0.80),1,as.numeric) + diag(-1,ncol(SampleCor))
SampleCorTrSubi
SampleCorTrSubi= graph_from_adjacency_matrix(SampleCorTrSubi, mode="undirected")
C5=cluster_louvain(SampleCorTrSubi)
plot(C5, SampleCorTrSubi,vertex.label=NA,edge.arrow.size=0.5,vertex.size=4)
table(C5$membership)
table(C5$membership, metadata$finegrain)
metadata$coarsegrain[C5$membership== 40,]
metadata$coarsegrain[C5$membership==40,]
metadata$coarsegrain[C5$membership=="40",]
metadata$coarsegrain[C5$membership=="40"]
metadata$coarsegrain[C5$membership=="44"]
metadata$finegrain[C5$membership=="44"]
metadata$finegrain[C5$membership=="40"]
table(C5$membership)
metadata$finegrain[C5$membership=="41"]
metadata$finegrain[C5$membership=="4"]
metadata$finegrain[C5$membership=="5"]
metadata$finegrain[C5$membership=="22"]
metadata$finegrain[C5$membership=="42"]
metadata$finegrain[C5$membership=="44"]
out= table(C5$membership)<15
table(C5$membership)[!out]
table(metadata[C5$membership==1, "coarsegrain"])
table(metadata[C5$membership==2, "coarsegrain"])
table(metadata[C5$membership==3, "coarsegrain"])
table(metadata[C5$membership==4, "coarsegrain"])
table(metadata[C5$membership==5, "coarsegrain"])
table(C5$membership)[!out]
table(metadata[C5$membership==12, "coarsegrain"])
table(metadata[C5$membership==20, "coarsegrain"])
table(metadata[C5$membership==21, "coarsegrain"])
table(metadata[C5$membership==23, "coarsegrain"])
table(metadata[C5$membership==43, "coarsegrain"])
table(metadata[C5$membership==46, "coarsegrain"])
table(metadata[C5$membership==47, "coarsegrain"])
metadata= metadata[C5$membership %in% names(table(C5$membership)[!out]),]
X=X[,metadata$samplename]
mdtrain = metadata[metadata$coarsegrain != "other" & metadata$coarsegrain != "noise",]
Trainsamples= NULL
Testsamples= NULL
set.seed(314)
for(i in unique(mdtrain$coarsegrain)){
len= sum(mdtrain$coarsegrain==i)*0.75
w= which(mdtrain[,"coarsegrain"]==i)
trains=sample(w,len,replace=FALSE)
tests= w[!w %in% trains]
Trainsamples=c(Trainsamples,trains)
Testsamples=c(Testsamples,tests)
}
Trainsamples=  mdtrain$samplename[Trainsamples]
Testsamples= mdtrain$samplename[Testsamples]
#Trainset
TRAINSET = "Train"
Xtrain = X[,Trainsamples]
mdtrain= metadata[Trainsamples,]
Types = unique(mdtrain$coarsegrain)
Type = mdtrain$coarsegrain
nusamples = 2000
props = matrix(runif(length(Types) * nusamples), ncol = nusamples)
M= matrix(rep(NA,length(Types) * nusamples),ncol=nusamples)
binom_prob= seq(0.1,0.7,by=0.1)
sample(binom_prob,1)
sample(binom_prob,1)
sample(binom_prob,1)
sample(binom_prob,1)
sample(binom_prob,1)
sample(binom_prob,1)
sample(binom_prob,1)
sample(binom_prob,1)
sample(binom_prob,1)
sample(binom_prob,1)
rbinom(nrow(M), 1, bp)
bp= sample(binom_prob,1)
binom= rbinom(nrow(M), 1, bp)
dist(binom)
binom
nrowm(M)
nrow(M)
for(i in 1:ncol(M)){
bp= sample(binom_prob,1)
binom= rbinom(nrow(M), 1, bp)
M[,i]=binom
}
M
dim(M)
comsum(M)
colsum(M)
colsums(M)
colSums(M)
max(M)
hist(M)
max(M)
max(colSums(M))
sample(1:nrow(M),1)
sample(1:nrow(M),1)
sample(1:nrow(M),1)
frequency(M)
frequency(M[,1])
frequency(colSums(M))
table(colSums(M))
proprs
props
props[1,]
table(colSums(M))
if(any(colSums(M) == 0)){
ind=which(colSums(M)==0)
for(j in ind){
ind2=sample(1:nrow(M),1)
M[ind2,j]=1
}
}
table(colSums(M))
dim(M)
table(rowSums(M))
rowSums(M)
rbinom(nrow(M), 1, bp)
rbinom(nrow(M), 1, bp)
rbinom(nrow(M), 1, bp)
?rbinom
M= matrix(rep(NA,length(Types) * nusamples),ncol=nusamples)
binom_prob= seq(0.1,0.7,by=0.1)
for(i in 1:ncol(M)){
bp= sample(binom_prob,1)
binom= rbinom(nrow(M), 1, bp)
M[,i]=binom
while(any(colSums(M) == 0)){
ind=which(colSums(M)==0)
for(j in ind){
bp= sample(binom_prob,1)
binom= rbinom(nrow(M), 1, bp)
M[,j]=binom
}
}
}
M= matrix(rep(NA,length(Types) * nusamples),ncol=nusamples)
binom_prob= seq(0.1,0.7,by=0.1)
for(i in 1:ncol(M)){
bp= sample(binom_prob,1)
binom= rbinom(nrow(M), 1, bp)
M[,i]=binom
}
while(any(colSums(M) == 0)){
ind=which(colSums(M)==0)
for(j in ind){
bp= sample(binom_prob,1)
binom= rbinom(nrow(M), 1, bp)
M[,j]=binom
}
}
colSums(M)
table(colSums(M))
props = props * M
rm(M)
props = apply(props, 2, function(x) x / sum(x))
exp = matrix(rep(0, nrow(Xtrain) * ncol(props)), ncol = ncol(props))
for (j in 1:ncol(props)) {
for (i in 1:length(Types)) {
if(props[i, j]==0){next}
#select cell type to mix
s = which(Type == Types[i])
#Decide how many samples of the cell type are going to be mixed
numofsamples= sample(1:length(s),1)
#Determine sampling probabilities according batch and finegrain type
Factor= paste(mdtrain[s,"batch"],mdtrain[s,"finegrain"],sep=".")
sampling_prob= (1/length(unique(Factor))) /table(Factor)
sampling_prob= sampling_prob[Factor]
l= sample(s,numofsamples,replace=FALSE,prob=sampling_prob)
sampleprop = runif(numofsamples)
#sampleprop = runif(sum(Type == Types[i]))
sampleprop = sampleprop / sum(sampleprop)
EXPi = rowSums(t(t(Xtrain[, l]) * sampleprop))
exp[, j] = exp[, j] + EXPi * props[i, j]
}
}
train = exp
trainprop = props
colnames(train) = 1:ncol(train)
rownames(train) = rownames(Xtrain)
rownames(trainprop) = Types
#Test set
TESTSET = "Test"
Xtest = X[, Testsamples]
mdtest = metadata[Testsamples,]
Types = unique(mdtest$coarsegrain)
Type = mdtest$coarsegrain
nusamples = 1000
props = matrix(runif(length(Types) * nusamples), ncol = nusamples)
M= matrix(rep(NA,length(Types) * nusamples),ncol=nusamples)
M= matrix(rep(NA,length(Types) * nusamples),ncol=nusamples)
binom_prob= seq(0.1,0.7,by=0.1)
for(i in 1:ncol(M)){
bp= sample(binom_prob,1)
binom= rbinom(nrow(M), 1, bp)
M[,i]=binom
}
while(any(colSums(M) == 0)){
ind=which(colSums(M)==0)
for(j in ind){
bp= sample(binom_prob,1)
binom= rbinom(nrow(M), 1, bp)
M[,j]=binom
}
}
props = props * M
rm(M)
props = apply(props, 2, function(x)
x / sum(x))
exp = matrix(rep(0, nrow(Xtrain) * ncol(props)), ncol = ncol(props))
for (j in 1:ncol(props)) {
for (i in 1:length(Types)) {
if(props[i, j]==0){next}
#select cell type to mix
s = which(Type == Types[i])
#Decide how many samples of the cell type are going to be mixed
numofsamples= sample(1:length(s),1)
#Determine sampling probabilities according batch and finegrain type
Factor= paste(mdtest[s,"batch"],mdtest[s,"finegrain"],sep=".")
sampling_prob= (1/length(unique(Factor))) /table(Factor)
sampling_prob= sampling_prob[Factor]
l= sample(s,numofsamples,replace=FALSE,prob=sampling_prob)
sampleprop = runif(numofsamples)
#sampleprop = runif(sum(Type == Types[i]))
sampleprop = sampleprop / sum(sampleprop)
EXPi = rowSums(t(t(Xtest[, l]) * sampleprop))
exp[, j] = exp[, j] + EXPi * props[i, j]
}
}
test = exp
testprop = props
colnames(test) = 1:ncol(test)
rownames(test) = rownames(Xtrain)
rownames(testprop) = Types
library(glmnet)
library(foreach)
library(tibble)
library(tibble)
library(doParallel)
library(dplyr)
library(optparse)
registerDoParallel(cores=6)
alpha_range <- c(0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9)
option_list <- list(
make_option("--experimenttag", action="store", type="character", default="default-experiment", help = "Set experiment tag id "),
make_option("--nfeature", action="store", type="numeric", default=500, help = "Set the maximun number of features ")
)
opt <- parse_args(OptionParser(option_list=option_list))
opt
parms <- expand.grid(alpha = alpha_range, lambda_ratio = lambda_ratio_range)
alpha_range <- c(0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9)
lambda_ratio_range <- c(10e-8,10e-7,10e-6,10e-5,10e-4,10e-3)
rownames(trainprop)
parms <- expand.grid(alpha = alpha_range, lambda_ratio = lambda_ratio_range)
results_final <-c()
results_final_models <- list()
parms
for (label_number in rownames(trainprop)) {
# Create datasets  ----------
labels <- trainprop[label_number, ]
trainset<- t(train)
labels_test <- testprop[label_number, ]
testset <- t(test)
results <- foreach(i = 1:nrow(parms),.packages = "glmnet",.combine = rbind) %dopar% {
alpha <- parms[i,]$alpha
lambda_ratio <- parms[i,]$lambda_ratio
model <- cv.glmnet(
type.measure = "mse",
nfolds = 5,
y = labels,
x = trainset,
alpha = alpha,
standardize = FALSE,
nlambda = 100,
lambda.min.ratio = lambda_ratio,
family = "gaussian",
lower.limit = -Inf
)
preds <- predict(model, testset,s = "lambda.1se")
spear <- cor(x = preds, y = labels_test, method = "spearman")
pears <- cor(x = preds, y = labels_test, method = "pearson")
partial_results<-data.frame(label_number,parms[i,], pearson = pears, spearman = spear)
partial_results
}
# Select best model ---------
best_model <- results %>% arrange(desc(pearson)) %>% filter(row_number()==1)
print(paste("selecting best model for ",best_model$label_number," : ",best_model$alpha, ", ", best_model$lambda_ratio," Pearson value : ", best_model$pearson,sep=""))
trainset <- rbind(trainset,testset)
labels <- c(labels,labels_test)
model <- cv.glmnet(
type.measure = "mse",
nfolds = 5,
y = labels,
x = trainset,
alpha = best_model$alpha,
standardize = FALSE,
nlambda = 100,
lambda.min.ratio = best_model$lambda_ratio,
family = "gaussian",
lower.limit = -Inf
)
results_final_models[[label_number]]<-model
save(results_final_models,file = paste0("results_glmnet_devcon_bestmodels_cgdata_cps_att_sq",opt$experimenttag,".rdata"),compress = "gzip")
results_final<-rbind(results_final,results)
readr::write_csv(results_final,path=paste0("results_glmnet_devcon_cgdata_cps_att_sq",opt$experimenttag,".csv"))
}
rownames(trainprop)
